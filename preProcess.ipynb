{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.ticker as mtick\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "input_file = os.path.join(current_path, \"test.amr\")\n",
    "audio = AudioSegment.from_file(input_file, format=\"amr\")\n",
    "audio.export(\"output_preprocess_raw.wav\", format=\"wav\")\n",
    "wave_file = os.path.join(current_path, \"output_preprocess_raw.wav\")\n",
    "wave_file_vad = wave_file.split(\".\")[0] + \"_vad.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print(bl=True, s=None):\n",
    "    if bl:\n",
    "        print(s)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spectrogram:\n",
    "    \"\"\"声谱图（语谱图）特征\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_file,\n",
    "        sr=None,\n",
    "        frame_len=512,\n",
    "        n_fft=None,\n",
    "        win_step=2 / 3,\n",
    "        window=\"hamming\",\n",
    "        preemph=0.97,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_file: 输入音频文件\n",
    "        :param sr: 所输入音频文件的采样率，默认为None\n",
    "        :param frame_len: 帧长，默认512个采样点(32ms,16kHz),与窗长相同\n",
    "        :param n_fft: FFT窗口的长度，默认与窗长相同\n",
    "        :param win_step: 窗移，默认移动2/3，512*2/3=341个采样点(21ms,16kHz)\n",
    "        :param window: 窗类型，默认汉明窗\n",
    "        :param preemph: 预加重系数,默认0.97\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.wave_data, self.sr = librosa.load(\n",
    "            self.input_file, sr=sr\n",
    "        )  # 音频全部采样点的归一化数组形式数据\n",
    "        self.wave_data = librosa.effects.preemphasis(\n",
    "            self.wave_data, coef=preemph\n",
    "        )  # 预加重，系数0.97\n",
    "        self.window_len = frame_len  # 窗长512\n",
    "        if n_fft is None:\n",
    "            self.fft_num = self.window_len  # 设置NFFT点数与窗长相等\n",
    "        else:\n",
    "            self.fft_num = n_fft\n",
    "        self.hop_length = round(\n",
    "            self.window_len * win_step\n",
    "        )  # 重叠部分采样点数设置为窗长的1/3（1/3~1/2）,即帧移(窗移)2/3\n",
    "        self.window = window\n",
    "\n",
    "    def get_magnitude_spectrogram(self):\n",
    "        \"\"\"\n",
    "        获取幅值谱:fft后取绝对值\n",
    "        :return: np.ndarray[shape=(1 + n_fft/2, n_frames), dtype=float32]，（257，全部采样点数/(512*2/3)+1）\n",
    "        \"\"\"\n",
    "        # 频谱矩阵：行数=1 + n_fft/2=257，列数=帧数n_frames=全部采样点数/(512*2/3)+1（向上取整）\n",
    "        # 快速傅里叶变化+汉明窗\n",
    "        mag_spec = np.abs(\n",
    "            librosa.stft(\n",
    "                self.wave_data,\n",
    "                n_fft=self.fft_num,\n",
    "                hop_length=self.hop_length,\n",
    "                win_length=self.window_len,\n",
    "                window=self.window,\n",
    "            )\n",
    "        )\n",
    "        return mag_spec\n",
    "\n",
    "    def get_power_spectrogram(self):\n",
    "        \"\"\"\n",
    "        获取功率谱（能量谱）：幅值谱平方\n",
    "        :return: np.ndarray[shape=(1 + n_fft/2, n_frames), dtype=float32]，（257，全部采样点数/(512*2/3)+1）\n",
    "        \"\"\"\n",
    "        pow_spec = np.square(self.get_magnitude_spectrogram())\n",
    "        return pow_spec\n",
    "\n",
    "    def get_log_power_spectrogram(self):\n",
    "        \"\"\"\n",
    "        获取log尺度功率谱（能量谱）：幅值谱平方S(也就是功率谱),10 * log10(S / ref),其中ref指定为S的最大值\n",
    "        :return: np.ndarray[shape=(1 + n_fft/2, n_frames), dtype=float32]，（257，全部采样点数/(512*2/3)+1）\n",
    "        \"\"\"\n",
    "        log_pow_spec = librosa.amplitude_to_db(\n",
    "            self.get_magnitude_spectrogram(), ref=np.max\n",
    "        )  # 转换为log尺度\n",
    "        return log_pow_spec\n",
    "\n",
    "    def get_mel_spectrogram(self, n_mels=26):\n",
    "        \"\"\"\n",
    "        获取Mel谱:\n",
    "        :param n_mels: Mel滤波器组的滤波器数量，默认26\n",
    "        :return: np.ndarray[shape=(n_mels, n_frames), dtype=float32]，（26，全部采样点数/(512*2/3)+1）\n",
    "        \"\"\"\n",
    "        # 频谱矩阵：行数=n_mels=26，列数=帧数n_frames=全部采样点数/(512*2/3)+1（向上取整）\n",
    "        # 快速傅里叶变化+汉明窗,Mel滤波器组的滤波器数量 = 26\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            self.wave_data,\n",
    "            self.sr,\n",
    "            n_fft=self.fft_num,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.window_len,\n",
    "            window=self.window,\n",
    "            n_mels=n_mels,\n",
    "        )\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec)  # 转换为log尺度\n",
    "        return log_mel_spec\n",
    "\n",
    "    def plot(self, fig=None, show=True, **kwargs):\n",
    "        \"\"\"\n",
    "        绘制声谱图\n",
    "        :param fig: 指定绘制何种声谱图，mag/pow/log_pow/mel,默认都绘制\n",
    "        :param show: 默认最后调用plt.show()，显示图形\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if fig == \"mag\":\n",
    "            mag_spec = self.get_magnitude_spectrogram()\n",
    "            librosa.display.specshow(\n",
    "                mag_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"linear\",\n",
    "            )\n",
    "            plt.title(\"Magnitude Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7)\n",
    "        elif fig == \"pow\":\n",
    "            pow_spec = self.get_power_spectrogram()\n",
    "            librosa.display.specshow(\n",
    "                pow_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"linear\",\n",
    "            )\n",
    "            plt.title(\"Power Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7)\n",
    "        elif fig == \"log_pow\":\n",
    "            log_pow_spec = self.get_log_power_spectrogram()\n",
    "            librosa.display.specshow(\n",
    "                log_pow_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"log\",\n",
    "            )\n",
    "            plt.title(\"Log-Power Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7, format=\"%+02.0f dB\")\n",
    "        elif fig == \"mel\":\n",
    "            mel_spec = self.get_mel_spectrogram(**kwargs)\n",
    "            librosa.display.specshow(\n",
    "                mel_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"mel\",\n",
    "            )\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.title(\"Log-Mel Spectrogram\")\n",
    "            plt.colorbar(shrink=0.7, format=\"%+02.0f dB\")\n",
    "        else:\n",
    "            plt.figure(figsize=(16, 8))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            mag_spec = self.get_magnitude_spectrogram()\n",
    "            librosa.display.specshow(\n",
    "                mag_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"linear\",\n",
    "            )\n",
    "            plt.title(\"Magnitude Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7)\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "            pow_spec = self.get_power_spectrogram()\n",
    "            librosa.display.specshow(\n",
    "                pow_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"linear\",\n",
    "            )\n",
    "            plt.title(\"Power Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7)\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            log_pow_spec = self.get_log_power_spectrogram()\n",
    "            librosa.display.specshow(\n",
    "                log_pow_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"linear\",\n",
    "            )\n",
    "            plt.title(\"Log-Power Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            # plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7, format=\"%+02.0f dB\")\n",
    "\n",
    "            plt.subplot(2, 2, 4)\n",
    "            mel_spec = self.get_mel_spectrogram(**kwargs)\n",
    "            librosa.display.specshow(\n",
    "                mel_spec,\n",
    "                sr=self.sr,\n",
    "                hop_length=self.hop_length,\n",
    "                x_axis=\"s\",\n",
    "                y_axis=\"mel\",\n",
    "            )\n",
    "            plt.title(\"Log-Mel Spectrogram\")\n",
    "            plt.xlabel(\"Time/ms\")\n",
    "            plt.ylabel(\"Frequency/Hz\")\n",
    "            plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "            plt.colorbar(shrink=0.7, format=\"%+02.0f dB\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhythmFeatures:\n",
    "    \"\"\"韵律学特征\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_file,\n",
    "        sr=None,\n",
    "        frame_len=512,\n",
    "        n_fft=None,\n",
    "        win_step=2 / 3,\n",
    "        window=\"hamming\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_file: 输入音频文件\n",
    "        :param sr: 所输入音频文件的采样率，默认为None\n",
    "        :param frame_len: 帧长，默认512个采样点(32ms,16kHz),与窗长相同\n",
    "        :param n_fft: FFT窗口的长度，默认与窗长相同\n",
    "        :param win_step: 窗移，默认移动2/3，512*2/3=341个采样点(21ms,16kHz)\n",
    "        :param window: 窗类型，默认汉明窗\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.frame_len = frame_len  # 帧长，单位采样点数\n",
    "        self.wave_data, self.sr = librosa.load(self.input_file, sr=sr)\n",
    "        self.window_len = frame_len  # 窗长512\n",
    "        if n_fft is None:\n",
    "            self.fft_num = self.window_len  # 设置NFFT点数与窗长相等\n",
    "        else:\n",
    "            self.fft_num = n_fft\n",
    "        self.win_step = win_step\n",
    "        self.hop_length = round(\n",
    "            self.window_len * win_step\n",
    "        )  # 重叠部分采样点数设置为窗长的1/3（1/3~1/2）,即帧移(窗移)2/3\n",
    "        self.window = window\n",
    "\n",
    "    def lld(self, **kwargs):\n",
    "        \"\"\"\n",
    "        LLDs（low level descriptors）指的是手工设计的一些低水平特征。\n",
    "        LLDs一般是在一帧frame语音上进行的计算，是用来表示一帧语音的特征。\n",
    "        :param kwargs: activity_detect参数\n",
    "        :return: 浊音(1，n)、轻音段(1，2*n)、有效语音段持续时间(1，n)，单位ms,numpy.uint32\n",
    "                基频F0，单位Hz、一阶、二阶差分(1，按列拉直提取非0元素后个数，>=n_frames),numpy.float32\n",
    "                对数能量值、一阶、二阶差分(1，n_frames),numpy.float32\n",
    "                短时能量、一阶、二阶差分(1，无加窗n_frames),numpy.float64\n",
    "                过零率，单位次,uint32、一阶、二阶差分(1，无加窗n_frames),numpy.float64\n",
    "                声压级，单位dB、一阶、二阶差分(1，无加窗n_frames),numpy.float64\n",
    "        \"\"\"\n",
    "        duration_voiced, duration_unvoiced, duration_all = self.duration(**kwargs)\n",
    "        f0, mag = self.pitch()\n",
    "        f0 = f0.T[np.nonzero(f0.T)]  # 按列提取非0元素，组成一维数组\n",
    "        f0_de = librosa.feature.delta(f0, width=3)\n",
    "        f0_de2 = librosa.feature.delta(f0, width=3, order=2)\n",
    "        energy = np.log(self.energy())\n",
    "        energy_de = librosa.feature.delta(energy, width=3)\n",
    "        energy_de2 = librosa.feature.delta(energy, width=3, order=2)\n",
    "        ste = self.short_time_energy()\n",
    "        ste_de = librosa.feature.delta(ste, width=3)\n",
    "        ste_de2 = librosa.feature.delta(ste, width=3, order=2)\n",
    "        zcr = self.zero_crossing_rate()\n",
    "        zcr_de = librosa.feature.delta(zcr, width=3)\n",
    "        zcr_de2 = librosa.feature.delta(zcr, width=3, order=2)\n",
    "        spl = self.intensity()\n",
    "        spl_de = librosa.feature.delta(spl, width=3)\n",
    "        spl_de2 = librosa.feature.delta(spl, width=3, order=2)\n",
    "        return (\n",
    "            duration_voiced,\n",
    "            duration_unvoiced,\n",
    "            duration_all,\n",
    "            f0,\n",
    "            f0_de,\n",
    "            f0_de2,\n",
    "            energy,\n",
    "            energy_de,\n",
    "            energy_de2,\n",
    "            ste,\n",
    "            ste_de,\n",
    "            ste_de2,\n",
    "            zcr,\n",
    "            zcr_de,\n",
    "            zcr_de2,\n",
    "            spl,\n",
    "            spl_de,\n",
    "            spl_de2,\n",
    "        )\n",
    "\n",
    "    def hsf(self, **kwargs):\n",
    "        \"\"\"\n",
    "        HSFs（high level statistics functions）是在LLDs的基础上做一些统计而得到的特征，比如均值，最值等。\n",
    "        HSFs是对一段语音utterance上的多帧语音做统计，是用来表示一个utterance的特征。\n",
    "        :param kwargs: lld参数:activity_detect参数\n",
    "        :return: 1*120维HSFs特征,numpy.float64: 浊音/轻音/有效语音段duration的最小值/最大值/极差/均值/标准差（第0-14维）；\n",
    "                 F0/F0_de/F0_de2的最小值/最大值/极差/均值/标准差/偏度/峰度（第15-35维）；\n",
    "                 energy/energy_de/energy_de2的最小值/最大值/极差/均值/标准差/偏度/峰度（第36-56维）；\n",
    "                 ste/ste_de/ste_de2的最小值/最大值/极差/均值/标准差/偏度/峰度（第57-77维）；\n",
    "                 zcr/zcr_de/zcr_de2的最小值/最大值/极差/均值/标准差/偏度/峰度（第78-98维）；\n",
    "                 spl/spl_de/spl_de2的最小值/最大值/极差/均值/标准差/偏度/峰度（第99-119维）\n",
    "        \"\"\"\n",
    "        llds = self.lld(**kwargs)\n",
    "        hsfs = []\n",
    "        for i in range(len(llds)):\n",
    "            hsfs = np.append(\n",
    "                hsfs,\n",
    "                [\n",
    "                    np.min(llds[i]),\n",
    "                    np.max(llds[i]),\n",
    "                    np.ptp(llds[i]),\n",
    "                    np.mean(llds[i]),\n",
    "                    np.std(llds[i]),\n",
    "                ],\n",
    "            )\n",
    "            if i > 2:  # 前3个为duration，不计算其偏度和峰度\n",
    "                hsfs = np.append(hsfs, [skew(llds[i]), kurtosis(llds[i])])\n",
    "        return hsfs\n",
    "\n",
    "    def short_time_energy(self):\n",
    "        \"\"\"\n",
    "        计算语音短时能量：每一帧中所有语音信号的平方和\n",
    "        :return: 语音短时能量列表(值范围0-每帧归一化后能量平方和，这里帧长512，则最大值为512)，\n",
    "        np.ndarray[shape=(1，无加窗，帧移为0的n_frames), dtype=float64]\n",
    "        \"\"\"\n",
    "        energy = []  # 语音短时能量列表\n",
    "        energy_sum_per_frame = 0  # 每一帧短时能量累加和\n",
    "        for i in range(len(self.wave_data)):  # 遍历每一个采样点数据\n",
    "            energy_sum_per_frame += self.wave_data[i] ** 2  # 求语音信号能量的平方和\n",
    "            if (i + 1) % self.frame_len == 0:  # 一帧所有采样点遍历结束\n",
    "                energy.append(energy_sum_per_frame)  # 加入短时能量列表\n",
    "                energy_sum_per_frame = 0  # 清空和\n",
    "            elif i == len(self.wave_data) - 1:  # 不满一帧，最后一个采样点\n",
    "                energy.append(energy_sum_per_frame)  # 将最后一帧短时能量加入列表\n",
    "        energy = np.array(energy)\n",
    "        energy = np.where(\n",
    "            energy == 0, np.finfo(np.float64).eps, energy\n",
    "        )  # 避免能量值为0，防止后续取log出错(eps是取非负的最小值)\n",
    "        return energy\n",
    "\n",
    "    def zero_crossing_rate(self):\n",
    "        \"\"\"\n",
    "        计算语音短时过零率：单位时间(每帧)穿过横轴（过零）的次数\n",
    "        :return: 每帧过零率次数列表，np.ndarray[shape=(1，无加窗，帧移为0的n_frames), dtype=uint32]\n",
    "        \"\"\"\n",
    "        zcr = []  # 语音短时过零率列表\n",
    "        counting_sum_per_frame = 0  # 每一帧过零次数累加和，即过零率\n",
    "        for i in range(len(self.wave_data)):  # 遍历每一个采样点数据\n",
    "            if i % self.frame_len == 0:  # 开头采样点无过零，因此每一帧的第一个采样点跳过\n",
    "                continue\n",
    "            if self.wave_data[i] * self.wave_data[i - 1] < 0:  # 相邻两个采样点乘积小于0，则说明穿过横轴\n",
    "                counting_sum_per_frame += 1  # 过零次数加一\n",
    "            if (i + 1) % self.frame_len == 0:  # 一帧所有采样点遍历结束\n",
    "                zcr.append(counting_sum_per_frame)  # 加入短时过零率列表\n",
    "                counting_sum_per_frame = 0  # 清空和\n",
    "            elif i == len(self.wave_data) - 1:  # 不满一帧，最后一个采样点\n",
    "                zcr.append(counting_sum_per_frame)  # 将最后一帧短时过零率加入列表\n",
    "        return np.array(zcr, dtype=np.uint32)\n",
    "\n",
    "    def energy(self):\n",
    "        \"\"\"\n",
    "        每帧内所有采样点的幅值平方和作为能量值\n",
    "        :return: 每帧能量值，np.ndarray[shape=(1，n_frames), dtype=float64]\n",
    "        \"\"\"\n",
    "        mag_spec = np.abs(\n",
    "            librosa.stft(\n",
    "                self.wave_data,\n",
    "                n_fft=self.fft_num,\n",
    "                hop_length=self.hop_length,\n",
    "                win_length=self.frame_len,\n",
    "                window=self.window,\n",
    "            )\n",
    "        )\n",
    "        pow_spec = np.square(mag_spec)\n",
    "        energy = np.sum(pow_spec, axis=0)\n",
    "        energy = np.where(\n",
    "            energy == 0, np.finfo(np.float64).eps, energy\n",
    "        )  # 避免能量值为0，防止后续取log出错(eps是取非负的最小值)\n",
    "        return energy\n",
    "\n",
    "    def intensity(self):\n",
    "        \"\"\"\n",
    "        计算声音强度，用声压级表示：每帧语音在空气中的声压级Sound Pressure Level(SPL)，单位dB\n",
    "        公式：20*lg(P/Pref)，P为声压（Pa），Pref为参考压力(听力阈值压力)，一般为2.0*10-5 Pa\n",
    "        这里P认定为声音的幅值：求得每帧所有幅值平方和均值，除以Pref平方，再取10倍lg\n",
    "        :return: 每帧声压级，dB，np.ndarray[shape=(1，无加窗，帧移为0的n_frames), dtype=float64]\n",
    "        \"\"\"\n",
    "        p0 = 2.0e-5  # 听觉阈限压力auditory threshold pressure: 2.0*10-5 Pa\n",
    "        e = self.short_time_energy()\n",
    "        spl = 10 * np.log10(1 / (np.power(p0, 2) * self.frame_len) * e)\n",
    "        return spl\n",
    "\n",
    "    def duration(self, **kwargs):\n",
    "        \"\"\"\n",
    "        持续时间：浊音、轻音段持续时间，有效语音段持续时间,一段有效语音段由浊音段+浊音段两边的轻音段组成\n",
    "        :param kwargs: activity_detect参数\n",
    "        :return: np.ndarray[dtype=uint32],浊音shape=(1，n)、轻音段shape=(1，2*n)、有效语音段持续时间列表shape=(1，n)，单位ms\n",
    "        \"\"\"\n",
    "        wav_dat_split_f, wav_dat_split, voiced_f, unvoiced_f = self.activity_detect(\n",
    "            **kwargs\n",
    "        )  # 端点检测\n",
    "        duration_voiced = []  # 浊音段持续时间\n",
    "        duration_unvoiced = []  # 轻音段持续时间\n",
    "        duration_all = []  # 有效语音段持续时间\n",
    "        if np.array(voiced_f).size > 1:  # 避免语音过短，只有一帧浊音段\n",
    "            for voiced in voiced_f:  # 根据帧分割计算浊音段持续时间，两端闭区间\n",
    "                duration_voiced.append(\n",
    "                    round((voiced[1] - voiced[0] + 1) * self.frame_len / self.sr * 1000)\n",
    "                )\n",
    "        else:  # 只有一帧时\n",
    "            duration_voiced.append(round(self.frame_len / self.sr * 1000))\n",
    "        for unvoiced in unvoiced_f:  # 根据帧分割计算清音段持续时间，浊音段左侧左闭右开，浊音段右侧左开右闭\n",
    "            duration_unvoiced.append(\n",
    "                round((unvoiced[1] - unvoiced[0]) * self.frame_len / self.sr * 1000)\n",
    "            )\n",
    "        if len(duration_unvoiced) <= 1:  # 避免语音过短，只有一帧浊音段\n",
    "            duration_unvoiced.append(0)\n",
    "        for i in range(len(duration_voiced)):  # 浊音段+浊音段两边的轻音段组成一段有效语音段\n",
    "            duration_all.append(\n",
    "                duration_unvoiced[i * 2]\n",
    "                + duration_voiced[i]\n",
    "                + duration_unvoiced[i * 2 + 1]\n",
    "            )\n",
    "        return (\n",
    "            np.array(duration_voiced, dtype=np.uint32),\n",
    "            np.array(duration_unvoiced, dtype=np.uint32),\n",
    "            np.array(duration_all, dtype=np.uint32),\n",
    "        )\n",
    "\n",
    "    def pitch(self, ts_mag=0.25):\n",
    "        \"\"\"\n",
    "        获取每帧音高，即基频，这里应该包括基频和各次谐波，最小的为基频（一次谐波），其他的依次为二次、三次...谐波\n",
    "        各次谐波等于基频的对应倍数，因此基频也等于各次谐波除以对应的次数，精确些等于所有谐波之和除以谐波次数之和\n",
    "        :param ts_mag: 幅值倍乘因子阈值，>0，大于np.average(np.nonzero(magnitudes)) * ts_mag则认为对应的音高有效,默认0.25\n",
    "        :return: 每帧基频及其对应峰的幅值(>0)，\n",
    "                 np.ndarray[shape=(1 + n_fft/2，n_frames), dtype=float32]，（257，全部采样点数/(512*2/3)+1）\n",
    "        \"\"\"\n",
    "        mag_spec = np.abs(\n",
    "            librosa.stft(\n",
    "                self.wave_data,\n",
    "                n_fft=self.fft_num,\n",
    "                hop_length=self.hop_length,\n",
    "                win_length=self.frame_len,\n",
    "                window=self.window,\n",
    "            )\n",
    "        )\n",
    "        # pitches:shape=(d,t)  magnitudes:shape=(d.t), Where d is the subset of FFT bins within fmin and fmax.\n",
    "        # pitches[f,t] contains instantaneous frequency at bin f, time t\n",
    "        # magnitudes[f,t] contains the corresponding magnitudes.\n",
    "        # pitches和magnitudes大于maximal magnitude时认为是一个pitch，否则取0，maximal默认取threshold*ref(S)=1*mean(S, axis=0)\n",
    "        pitches, magnitudes = librosa.piptrack(\n",
    "            S=mag_spec, sr=self.sr, threshold=1.0, ref=np.mean, fmin=50, fmax=500\n",
    "        )  # 人类正常说话基频最大可能范围50-500Hz\n",
    "        ts = np.average(magnitudes[np.nonzero(magnitudes)]) * ts_mag\n",
    "        pit_likely = pitches\n",
    "        mag_likely = magnitudes\n",
    "        pit_likely[magnitudes < ts] = 0\n",
    "        mag_likely[magnitudes < ts] = 0\n",
    "        return pit_likely, mag_likely\n",
    "\n",
    "    def activity_detect(\n",
    "        self, min_interval=15, e_low_multifactor=1.0, zcr_multifactor=1.0, pt=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        利用短时能量，短时过零率，使用双门限法进行端点检测\n",
    "        :param min_interval: 最小浊音间隔，默认15帧\n",
    "        :param e_low_multifactor: 能量低阈值倍乘因子，默认1.0\n",
    "        :param zcr_multifactor: 过零率阈值倍乘因子，默认1.0\n",
    "        :param pt: 输出打印标志位，默认为False\n",
    "        :return: 全部有效语音段:按帧分割后(list,n*2)、按全部采样点的幅值分割(np.ndarray[shape=(n, 采样值数), dtype=float32])、\n",
    "                浊音段(list,n*2)、轻音段(list,n*2)\n",
    "        \"\"\"\n",
    "        ste = self.short_time_energy()\n",
    "        zcr = self.zero_crossing_rate()\n",
    "        energy_average = sum(ste) / len(ste)  # 求全部帧的短时能量均值\n",
    "        energy_high = energy_average / 4  # 能量均值的4分之一作为能量高阈值\n",
    "        energy_low = (\n",
    "            sum(ste[:5]) / 5 + energy_high / 5\n",
    "        ) * e_low_multifactor  # 前5帧能量均值+能量高阈值的5分之一作为能量低阈值\n",
    "        zcr_threshold = (\n",
    "            sum(zcr) / len(zcr) * zcr_multifactor\n",
    "        )  # 过零率均值*zcr_multfactor作为过零率阈值\n",
    "        voiced_sound = []  # 语音段的浊音部分\n",
    "        voiced_sound_added = []  # 浊音扩充后列表\n",
    "        wave_detected = []  # 轻音扩充后的最终列表\n",
    "        # 首先利用能量高阈值energy_high进行初步检测，得到语音段的浊音部分\n",
    "        add_flag = True  # 加入voiced_sound列表标志位\n",
    "        for i in range(len(ste)):  # 遍历短时能量数据\n",
    "            if len(voiced_sound) == 0 and add_flag and ste[i] >= energy_high:  # 第一次达到阈值\n",
    "                voiced_sound.append(i)  # 加入列表\n",
    "                add_flag = False  # 接下来禁止加入\n",
    "            if (not add_flag) and ste[i] < energy_high:  # 直到未达到阈值，此时该阶段为一段浊音语音\n",
    "                if i - voiced_sound[-1] <= 2:  # 检测帧索引间隔，去掉间隔小于2的索引，判断该段为噪音\n",
    "                    voiced_sound = voiced_sound[:-1]  # 该段不加入列表\n",
    "                else:  # 否则加入列表\n",
    "                    voiced_sound.append(i)\n",
    "                add_flag = True  # 继续寻找下一段浊音（下一个阈值）\n",
    "            # 再次达到阈值，判断两个浊音间隔是否大于最小浊音间隔\n",
    "            elif (\n",
    "                add_flag\n",
    "                and ste[i] >= energy_high\n",
    "                and i - voiced_sound[-1] > min_interval\n",
    "            ):\n",
    "                voiced_sound.append(i)  # 大于，则分段，加入列表\n",
    "                add_flag = False  # 接下来禁止加入\n",
    "            elif (\n",
    "                add_flag\n",
    "                and ste[i] >= energy_high\n",
    "                and i - voiced_sound[-1] <= min_interval\n",
    "            ):\n",
    "                voiced_sound = voiced_sound[:-1]  # 小于，则不分段，该段不加入列表\n",
    "                add_flag = False  # 接下来禁止加入\n",
    "            if (i == len(ste) - 1) and (\n",
    "                len(voiced_sound) % 2 == 1\n",
    "            ):  # 当到达最后一帧，发现浊音段为奇数，则此时到最后一帧为浊音段\n",
    "                if i - voiced_sound[-1] <= 2:  # 检测帧索引间隔，去掉间隔小于2的索引，判断该段为噪音\n",
    "                    voiced_sound = voiced_sound[:-1]  # 该段不加入列表\n",
    "                else:  # 否则加入列表\n",
    "                    voiced_sound.append(i)\n",
    "        _print(pt, \"能量高阈值:{}，浊音段:{}\".format(energy_high, voiced_sound))\n",
    "        # 再通过能量低阈值energy_low在浊音段向两端进行搜索，超过energy_low便视为有效语音\n",
    "        for j in range(len(voiced_sound)):  # 遍历浊音列表\n",
    "            i_minus_flag = False  # i值减一标志位\n",
    "            i = voiced_sound[j]  # 浊音部分帧索引\n",
    "            if j % 2 == 1:  # 每段浊音部分的右边帧索引\n",
    "                while i < len(ste) and ste[i] >= energy_low:  # 搜索超过能量低阈值的帧索引\n",
    "                    i += 1  # 向右搜索\n",
    "                voiced_sound_added.append(i)  # 搜索到则加入扩充列表，右闭\n",
    "            else:  # 每段浊音部分的左边帧索引\n",
    "                while i > 0 and ste[i] >= energy_low:  # 搜索超过能量低阈值的帧索引\n",
    "                    i -= 1  # 向左搜索\n",
    "                    i_minus_flag = True  # i值减一标志位置位\n",
    "                if i_minus_flag:  # 搜索到则加入扩充列表，左闭\n",
    "                    voiced_sound_added.append(i + 1)\n",
    "                else:\n",
    "                    voiced_sound_added.append(i)\n",
    "        _print(pt, \"能量低阈值:{}，浊音再次扩展后:{}\".format(energy_low, voiced_sound_added))\n",
    "        # 最后通过过零率对浊音扩充后列表向两端再次进行搜索，获取轻音部分\n",
    "        for j in range(len(voiced_sound_added)):  # 遍历浊音扩充后列表\n",
    "            i_minus_flag = False  # i值减一标志位\n",
    "            i = voiced_sound_added[j]  # 浊音扩充后部分帧索引\n",
    "            if j % 2 == 1:  # 每段浊音扩充部分的右边帧索引\n",
    "                while i < len(zcr) and zcr[i] >= zcr_threshold:  # 搜索超过过零率阈值的帧索引\n",
    "                    i += 1  # 向右搜索\n",
    "                wave_detected.append(i)  # 搜索到则加入扩充列表，右开\n",
    "            else:  # 每段浊音扩充部分的左边帧索引\n",
    "                while i > 0 and zcr[i] >= zcr_threshold:  # 搜索超过过零率阈值的帧索引\n",
    "                    i -= 1  # 向左搜索\n",
    "                    i_minus_flag = True  # i值减一标志位置位\n",
    "                if i_minus_flag:  # 搜索到则加入扩充列表，左闭\n",
    "                    wave_detected.append(i + 1)\n",
    "                else:\n",
    "                    wave_detected.append(i)\n",
    "        _print(pt, \"过零率阈值:{}，轻音段增加后:{}\".format(zcr_threshold, wave_detected))\n",
    "        wave_data_detected_frame = []  # 端点检测后，以帧为单位的有效语音列表\n",
    "        for index in range(len(wave_detected)):\n",
    "            if index % 2 == 0:  # 按段分割成列表\n",
    "                wave_data_detected_frame.append(wave_detected[index : index + 2])\n",
    "            else:\n",
    "                continue\n",
    "        _print(\n",
    "            pt,\n",
    "            \"分割后共{}段语音，按帧分割为{}\".format(\n",
    "                len(wave_data_detected_frame), wave_data_detected_frame\n",
    "            ),\n",
    "        )\n",
    "        wave_data_detected = []  # 端点检测后，对应全部采样点的幅值列表，其中列表代表每个有效语音段\n",
    "        for index in wave_data_detected_frame:\n",
    "            try:\n",
    "                wave_data_detected.append(\n",
    "                    self.wave_data[\n",
    "                        index[0] * int(self.frame_len) : index[1] * int(self.frame_len)\n",
    "                    ]\n",
    "                )\n",
    "            except IndexError:\n",
    "                wave_data_detected.append(\n",
    "                    self.wave_data[index[0] * int(self.frame_len) : -1]\n",
    "                )\n",
    "        _print(\n",
    "            pt,\n",
    "            \"分割后共{}段语音，按全部采样点的幅值分割为{}\".format(\n",
    "                len(wave_data_detected), wave_data_detected\n",
    "            ),\n",
    "        )\n",
    "        if np.array(voiced_sound_added).size > 1:  # 避免语音过短，只有一帧浊音段\n",
    "            voiced_frame = (\n",
    "                np.array(voiced_sound_added).reshape((-1, 2)).tolist()\n",
    "            )  # 按帧分割的浊音段\n",
    "        else:  # 只有一帧时\n",
    "            voiced_frame = np.array(voiced_sound_added).tolist()\n",
    "        unvoiced_frame = []  # 按帧分割的轻音段\n",
    "        for i in range(len(wave_detected)):  # 根据最终的扩充后列表和浊音段列表求得轻音段\n",
    "            if wave_detected[i] < voiced_sound_added[i]:\n",
    "                unvoiced_frame.append([wave_detected[i], voiced_sound_added[i]])\n",
    "            elif wave_detected[i] > voiced_sound_added[i]:\n",
    "                unvoiced_frame.append([voiced_sound_added[i], wave_detected[i]])\n",
    "            else:\n",
    "                unvoiced_frame.append([0, 0])\n",
    "        return (\n",
    "            wave_data_detected_frame,  # 端点检测后，以帧为单位的有效语音列表\n",
    "            wave_data_detected,  # 端点检测后，对应全部采样点的幅值列表，其中列表代表每个有效语音段\n",
    "            voiced_frame,  # 按帧分割的浊音段\n",
    "            unvoiced_frame,  # 按帧分割的轻音段\n",
    "        )\n",
    "\n",
    "    def plot(self, energy=\"ste\", show=True):\n",
    "        \"\"\"\n",
    "        绘制语音波形曲线和（短时）能量、过零率曲线叠加，log功率谱和基频、声压级曲线叠加图\n",
    "        :param energy: \"ste\"短时能量，\"energy\"能量，默认\"ste\"\n",
    "        :param show: 默认最后调用plt.show()，显示图形\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        # 以下绘制波形图\n",
    "        wave_ax = host_subplot(211, axes_class=AA.Axes)  # type:AA.Axes\n",
    "        wave_ax.set_title(\"Wave Form\")\n",
    "        aa = wave_ax.axis[\"left\"]  # type:AA.axis_artist.AxisArtist\n",
    "        aa.line.set_color(\"b\")\n",
    "        aa.major_ticks.set_color(\"b\")\n",
    "        aa.major_ticklabels.set_color(\"b\")\n",
    "        wave_ax.set_xticks([])\n",
    "        audio_total_time = int(len(self.wave_data) / self.sr * 1000)  # 音频总时间ms\n",
    "        wave_ax.set_xlim(0, audio_total_time)\n",
    "        wave_ax.set_ylabel(\"Normalized Amplitude\", c=\"b\")\n",
    "        wave_ax.set_ylim(-1, 1)\n",
    "        x = np.linspace(0, audio_total_time, len(self.wave_data))  # 从0ms开始，到总时长结束，共采样点数\n",
    "        wave_ax.plot(x, self.wave_data, c=\"b\", lw=1, label=\"wave curve\")  # 语音波形曲线\n",
    "        wave_ax.axhline(y=0, c=\"pink\", ls=\":\", lw=1)  # Y轴0线\n",
    "        # 以下在波形曲线上叠加绘制(短时)能量曲线\n",
    "        if energy == \"ste\":\n",
    "            e = self.short_time_energy()\n",
    "        elif energy == \"energy\":\n",
    "            e = self.energy()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Incorrect energy type parameter input, choose from 'ste' or 'energy'.\"\n",
    "            )\n",
    "        e_ax = wave_ax.twinx()  # type:AA.Axes  # 共享X轴\n",
    "        aa = e_ax.axis[\"right\"]  # type:AA.axis_artist.AxisArtist\n",
    "        aa.toggle(all=True)\n",
    "        aa.line.set_color(\"r\")\n",
    "        aa.major_ticks.set_color(\"r\")\n",
    "        aa.major_ticklabels.set_color(\"r\")\n",
    "        e_ax.set_ylabel(\"Energy\", c=\"r\")\n",
    "        e_ax.set_ylim(0, np.max(e))\n",
    "        x = np.linspace(\n",
    "            self.frame_len / self.sr * 1000, audio_total_time, len(e)\n",
    "        )  # 从第1帧结束对应时间开始，到总时长结束\n",
    "        x = np.append(0, x)  # 第1帧时间之前补一个点：（0,0）\n",
    "        e = np.append(0, e)\n",
    "        if energy == \"ste\":\n",
    "            e_ax.plot(x, e, c=\"r\", lw=1.5, label=\"short time energy\")\n",
    "        else:\n",
    "            e_ax.plot(x, e, c=\"r\", lw=1.5, label=\"energy\")\n",
    "        # 以下在波形曲线上再次叠加绘制过零率曲线\n",
    "        zcr = self.zero_crossing_rate()\n",
    "        zcr_ax = wave_ax.twinx()  # type:AA.Axes\n",
    "        zcr_ax.axis[\"right\"] = zcr_ax.get_grid_helper().new_fixed_axis(\n",
    "            loc=\"right\", axes=zcr_ax, offset=(45, 0)\n",
    "        )\n",
    "        aa = zcr_ax.axis[\"right\"]  # type:AA.axis_artist.AxisArtist\n",
    "        aa.toggle(all=True)\n",
    "        aa.line.set_color(\"g\")\n",
    "        aa.major_ticks.set_color(\"g\")\n",
    "        aa.major_ticklabels.set_color(\"g\")\n",
    "        zcr_ax.set_ylabel(\"Times of Zero Crossing\", c=\"g\")\n",
    "        zcr_ax.set_ylim(0, np.max(zcr))\n",
    "        x = np.linspace(\n",
    "            self.frame_len / self.sr * 1000, audio_total_time, len(zcr)\n",
    "        )  # 从第1帧结束对应时间开始，到总时长结束\n",
    "        x = np.append(0, x)  # 第1帧时间之前补一个点：（0,0）\n",
    "        zcr = np.append(0, zcr)\n",
    "        zcr_ax.plot(x, zcr, c=\"g\", lw=1.5, label=\"zero crossing rate\")\n",
    "        wave_ax.legend(\n",
    "            prop={\"family\": \"Times New Roman\", \"size\": 10},\n",
    "            loc=\"upper right\",\n",
    "            framealpha=0.5,\n",
    "            ncol=3,\n",
    "            handletextpad=0.2,\n",
    "            columnspacing=0.7,\n",
    "        )\n",
    "        # 以下绘制灰度对数功率谱图\n",
    "        spec = Spectrogram(\n",
    "            self.input_file,\n",
    "            self.sr,\n",
    "            self.frame_len,\n",
    "            self.fft_num,\n",
    "            self.win_step,\n",
    "            self.window,\n",
    "            0,\n",
    "        )\n",
    "        log_power_spec = librosa.amplitude_to_db(\n",
    "            spec.get_magnitude_spectrogram(), ref=np.max\n",
    "        )\n",
    "        log_power_spec_ax = host_subplot(212, axes_class=AA.Axes)  # type:AA.Axes\n",
    "        log_power_spec_ax.set_title(\"Pitches on Log-Power Spectrogram\")\n",
    "        librosa.display.specshow(\n",
    "            log_power_spec[:, 1:],\n",
    "            cmap=\"gray_r\",\n",
    "            sr=self.sr,\n",
    "            hop_length=self.hop_length,\n",
    "            x_axis=\"s\",\n",
    "            y_axis=\"linear\",\n",
    "        )\n",
    "        log_power_spec_ax.set_xlabel(\"Time/ms\")\n",
    "        log_power_spec_ax.set_ylabel(\"Frequency/Hz\")\n",
    "        log_power_spec_ax.xaxis.set_major_formatter(mtick.FuncFormatter(func_format))\n",
    "        # 以下在灰度对数功率谱图上叠加绘制pitches中可能的基频F0点图\n",
    "        pitches, mags = self.pitch()  # 获取每帧基频\n",
    "        f0_likely = []  # 可能的基频F0\n",
    "        for i in range(pitches.shape[1]):  # 按列遍历非0最小值，作为每帧可能的F0\n",
    "            try:\n",
    "                f0_likely.append(np.min(pitches[np.nonzero(pitches[:, i]), i]))\n",
    "            except ValueError:\n",
    "                f0_likely.append(np.nan)  # 当一列，即一帧全为0时，赋值最小值为nan\n",
    "        f0_all = np.array(f0_likely)\n",
    "        x = np.linspace(\n",
    "            0.5 * self.hop_length / self.sr, audio_total_time / 1000, f0_all.size\n",
    "        )\n",
    "        y = f0_all\n",
    "        f0_all_ax = log_power_spec_ax.twinx()  # type:AA.Axes  # 共享X轴\n",
    "        aa = f0_all_ax.axis[\"right\"]  # type:AA.axis_artist.AxisArtist\n",
    "        aa.toggle(all=True)\n",
    "        aa.line.set_color(\"r\")\n",
    "        aa.major_ticks.set_color(\"r\")\n",
    "        aa.major_ticklabels.set_color(\"r\")\n",
    "        f0_all_ax.set_ylabel(\"Pitches/Hz\", c=\"r\")\n",
    "        f0_all_ax.set_ylim(50, 500)\n",
    "        f0_all_ax.scatter(x, y, s=10, c=\"r\", label=\"F0\")\n",
    "        # 以下在灰度对数功率谱图上叠加绘制声压级曲线\n",
    "        spl = self.intensity()\n",
    "        x = np.linspace(\n",
    "            0.5 * self.frame_len / self.sr, audio_total_time / 1000, spl.size\n",
    "        )\n",
    "        y = spl\n",
    "        spl_ax = log_power_spec_ax.twinx()  # type:AA.Axes  # 共享X轴\n",
    "        spl_ax.axis[\"right\"] = spl_ax.get_grid_helper().new_fixed_axis(\n",
    "            loc=\"right\", axes=spl_ax, offset=(45, 0)\n",
    "        )\n",
    "        aa = spl_ax.axis[\"right\"]  # type:AA.axis_artist.AxisArtist\n",
    "        aa.toggle(all=True)\n",
    "        aa.line.set_color(\"g\")\n",
    "        aa.major_ticks.set_color(\"g\")\n",
    "        aa.major_ticklabels.set_color(\"g\")\n",
    "        spl_ax.set_ylabel(\"Intensity(SPL)/dB\", c=\"g\")\n",
    "        spl_ax.set_ylim(30, 100)\n",
    "        spl_ax.plot(x, y, \"g\", lw=1.5, label=\"SPL\")\n",
    "        plt.legend(\n",
    "            prop={\"family\": \"Times New Roman\", \"size\": 10},\n",
    "            loc=\"upper right\",\n",
    "            framealpha=0.5,\n",
    "            ncol=3,\n",
    "            handletextpad=0.2,\n",
    "            columnspacing=0.7,\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\PycharmProjects\\\\Speech_Depression\\\\output_preprocess_raw_vad.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VAD:\n",
    "    \"\"\"语音端点检测\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        wav_file,\n",
    "        frame_len=400,\n",
    "        min_interval=15,\n",
    "        e_low_multifactor=1.0,\n",
    "        zcr_multifactor=1.0,\n",
    "        pt=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        语音信号是非平稳信号，但是可以认为10~30ms的时间范围内，语音信号是平稳信号,比如这里我取25ms作为一帧\n",
    "        此时一帧包含25ms*采样率(16kHz)*通道数（1）=400个采样点\n",
    "        :param wav_file: 输入.wav音频文件\n",
    "        :param frame_len: 帧长，默认400个采样点\n",
    "        :param min_interval: 最小浊音间隔，默认15帧\n",
    "        :param e_low_multifactor: 能量低阈值倍乘因子，默认1.0\n",
    "        :param zcr_multifactor: 过零率阈值倍乘因子，默认1.0\n",
    "        :param pt: 输出打印标志位，默认为True\n",
    "        \"\"\"\n",
    "        rf = RhythmFeatures(wav_file, None, frame_len)\n",
    "        self.wave_data = rf.wave_data  # 获取音频全部采样点的数组形式数据,每个采样点类型为np.float32\n",
    "        self.sampling_rate = rf.sr\n",
    "        self.frame_len_samples = frame_len  # 帧长，单位采样点数\n",
    "        self.frame_len_time = round(\n",
    "            self.frame_len_samples * 1000 / self.sampling_rate\n",
    "        )  # 帧长，单位ms\n",
    "        self.energy = rf.short_time_energy()  # 获取短时能量\n",
    "        self.zcr = rf.zero_crossing_rate()  # 获取过零率\n",
    "        # 获取端点检测后的有效语音段\n",
    "        (\n",
    "            self.wav_dat_split_f,\n",
    "            self.wav_dat_split,\n",
    "            self.voiced_f,\n",
    "            self.unvoiced_f,\n",
    "        ) = rf.activity_detect(min_interval, e_low_multifactor, zcr_multifactor, pt)\n",
    "        # 语音首尾端点检测，中间不检测\n",
    "        if len(self.wav_dat_split_f[-1]) > 1:  # 避免语音过短，只有一帧\n",
    "            self.wav_dat_utterance = self.wave_data[\n",
    "                self.wav_dat_split_f[0][0]\n",
    "                * int(self.frame_len_samples) : self.wav_dat_split_f[-1][1]\n",
    "                * int(self.frame_len_samples)\n",
    "            ]\n",
    "        else:  # 只有一帧时\n",
    "            self.wav_dat_utterance = self.wave_data[\n",
    "                self.wav_dat_split_f[0][0] * int(self.frame_len_samples) :\n",
    "            ]\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        绘制音频波形、短时能量和过零率曲线\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        audio_total_time = int(len(self.wave_data) / self.sampling_rate * 1000)  # 音频总时间\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        # 以下绘制短时能量曲线\n",
    "        plt.subplot(1, 3, 2)\n",
    "        frames = [i for i in range(0, len(self.energy))]  # 横轴为帧数轴\n",
    "        plt.title(\"Short Time Energy\")\n",
    "        plt.xlabel(\"Frames\")\n",
    "        plt.ylabel(\"Energy\")\n",
    "        plt.plot(frames, self.energy, c=\"g\", lw=1)\n",
    "        plt.grid()\n",
    "        # 以下绘制过零率曲线\n",
    "        plt.subplot(1, 3, 3)\n",
    "        frames = [i for i in range(0, len(self.zcr))]  # 横轴为帧数轴\n",
    "        plt.title(\"Zero Crossing Rate\")\n",
    "        plt.xlabel(\"Frames\")\n",
    "        plt.ylabel(\"Times of Zero Crossing\")\n",
    "        plt.plot(frames, self.zcr, c=\"r\", lw=1)\n",
    "        plt.grid()\n",
    "        # 以下绘制语音波形曲线+端点检测分割线\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(\"%.1f\"))\n",
    "        time = [\n",
    "            int(i * (audio_total_time / len(self.wave_data)))\n",
    "            for i in range(0, len(self.wave_data))\n",
    "        ]\n",
    "        plt.title(\"Wave Form\")\n",
    "        plt.xlabel(\"Time/ms\")\n",
    "        plt.ylabel(\"Normalized Amplitude\")\n",
    "        plt.ylim(-1, 1)\n",
    "        plt.plot(time, self.wave_data, c=\"b\", lw=1)  # 语音波形曲线\n",
    "        c = \"g\"\n",
    "        for i in range(len(self.wav_dat_split_f)):  # 端点检测分割线\n",
    "            for j in range(len(self.wav_dat_split_f[i])):\n",
    "                if (i == 0 and j == 0) or (\n",
    "                    i == len(self.wav_dat_split_f) - 1 and j == 1\n",
    "                ):\n",
    "                    plt.axvline(\n",
    "                        x=self.wav_dat_split_f[i][j] * self.frame_len_time,\n",
    "                        c=c,\n",
    "                        ls=\"-\",\n",
    "                        lw=2,\n",
    "                    )\n",
    "                else:\n",
    "                    plt.axvline(\n",
    "                        x=self.wav_dat_split_f[i][j] * self.frame_len_time,\n",
    "                        c=c,\n",
    "                        ls=\"--\",\n",
    "                        lw=1.5,\n",
    "                    )\n",
    "            if c == \"r\":\n",
    "                c = \"g\"\n",
    "            else:\n",
    "                c = \"r\"\n",
    "        plt.grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot load library 'libsndfile.dll': error 0x7e",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\site-packages\\soundfile.py:161\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno packaged library for this platform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m_soundfile_data\u001b[39;00m  \u001b[38;5;66;03m# ImportError if this doesn't exist\u001b[39;00m\n\u001b[0;32m    162\u001b[0m _path \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(_soundfile_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)  \u001b[38;5;66;03m# TypeError if __file__ is None\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_soundfile_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\site-packages\\soundfile.py:170\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _libname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msndfile library not found using ctypes.util.find_library\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m _snd \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mdlopen(_libname)\n",
      "\u001b[1;31mOSError\u001b[0m: sndfile library not found using ctypes.util.find_library",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 读取音频文件\u001b[39;00m\n\u001b[0;32m      7\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_preprocess.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(audio_file, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 计算音频的短时能量\u001b[39;00m\n\u001b[0;32m     11\u001b[0m energy \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mrms(y\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\site-packages\\lazy_loader\\__init__.py:78\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     76\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[1;32m---> 78\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\site-packages\\lazy_loader\\__init__.py:77\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     76\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 77\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\site-packages\\librosa\\core\\audio.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msoundfile\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maudioread\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\speech_Depression\\lib\\site-packages\\soundfile.py:192\u001b[0m\n\u001b[0;32m    190\u001b[0m             _snd \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mdlopen(_os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_hbrew_path, _explicit_libname))\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m             _snd \u001b[38;5;241m=\u001b[39m \u001b[43m_ffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_explicit_libname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m __libsndfile_version__ \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mstring(_snd\u001b[38;5;241m.\u001b[39msf_version_string())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __libsndfile_version__\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibsndfile-\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mOSError\u001b[0m: cannot load library 'libsndfile.dll': error 0x7e"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取音频文件\n",
    "audio_file = \"output_preprocess.wav\"\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# 计算音频的短时能量\n",
    "energy = librosa.feature.rms(y=y)\n",
    "\n",
    "# 设置能量阈值\n",
    "energy_threshold = np.percentile(energy, 80)\n",
    "\n",
    "# 端点检测\n",
    "start_idx = 0\n",
    "end_idx = len(y) - 1\n",
    "for i in range(len(energy[0])):\n",
    "    if energy[0][i] > energy_threshold:\n",
    "        start_idx = i\n",
    "        break\n",
    "\n",
    "for i in range(len(energy[0]) - 1, 0, -1):\n",
    "    if energy[0][i] > energy_threshold:\n",
    "        end_idx = i\n",
    "        break\n",
    "\n",
    "# 去掉静音部分和主试噪音\n",
    "cleaned_audio = y[start_idx:end_idx]\n",
    "\n",
    "# 可视化展示前后的变化\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.waveplot(y, sr=sr)\n",
    "plt.title('Original Audio')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.waveplot(cleaned_audio, sr=sr)\n",
    "plt.title('Cleaned Audio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 输出端点位置\n",
    "print(\"Start point:\", start_idx)\n",
    "print(\"End point:\", end_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_Depression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
